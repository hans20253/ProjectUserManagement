{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I follow the algorithms and some of the prose in the article \"Tangent-space methods for uniform matrix product states\" by Laurens Vanderstraeten, Jutho Haegeman and Frank Verstraete published in January 2019 at\n",
    "SciPost: https://doi.org/10.21468/SciPostPhysLectNotes.7. (arXiV version: https://arxiv.org/abs/1810.07006.)\n",
    "\n",
    "This article has algorithms for both uniform-gauge and mixed-gauge TDVP.\n",
    "The mixed-gauge version is inverse free, at the cost of having a step in the time evolution that, at the time of my writing this notebook, remains elusive (magic) to me.\n",
    "\n",
    "I have so far only implemented \"one site\" TDVP, where the bond dimension remains constant.\n",
    "The same article has an algorithm (#3) for maximizing the overlap between two MPS, so in principle, one could implement that and have varying bond dimensions.\n",
    "*(gokhan, 24.05.2021: I don't understand anymore \"maximizing the overlap between two MPS => variable bond dimension\".)*\n",
    "Note that a subset of the authors has recently (January 2020) put a paper to arXiv titled \"Tangent-space methods for truncating uniform MPS\", https://arxiv.org/abs/2001.11882.\n",
    "For anyone who wants to vary the bond dimension it might be worth a read beforehand.\n",
    "\n",
    "The packages KrylovKit and TensorOperations are also by Jutho Haegeman.\n",
    "For time evolution, I use \"exponentiate\" from KrylovKit to\n",
    "exponentiate the effective Hamiltonians, one of which is a 3-tensor, in\n",
    "a matrix-free manner.\n",
    "I use it also for the matrix-free computations of fixed points of\n",
    "transfer tensors and similar constructs.\n",
    "\n",
    "----\n",
    "# Basic machinery\n",
    "We will often need to vectorize 3-tensors and take QR, RQ, polar and singular value decompositions.\n",
    "I will define the functions for them.\n",
    "First importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages used in this code\n",
    "using LinearAlgebra # Used for svd, qr.\n",
    "using TensorOperations # Used for @tensor\n",
    "using KrylovKit # Used for eigsolve, linsolve and exponentiate\n",
    "using EllipsisNotation # Used for ... slicing of arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site tensors\n",
    "We start out with a uniform gauge where the site tensor is $A$.\n",
    "In the code, site tensors, by my convention, have memory layout A[i,j,k] where $i$ is the left leg, $j$ is the physical leg, and $k$ is the right leg.\n",
    "\n",
    "Let's set the problem dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dH = 2; # Local Hilbert space dimension\n",
    "dBond = 3; # Bond dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create $A$ randomly, with contents drawn from $[0,1) + i[0,1)$.\n",
    "The contents will change upon normalization (and gauge changes).\n",
    "\n",
    "*TODO: Input/output such initial conditions. See for example Python codes at my finite TDVP repository.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = rand(ComplexF64, (dBond, dH, dBond));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing site tensors\n",
    "We will often need to pack the left leg and physical leg or the physical leg and the right leg to one \"packed leg\" in order to perform matrix decompositions, and then unpack them.\n",
    "Let's define some functions for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function leftPack(A)\n",
    "    dBond, dH = size(A)[1:2];\n",
    "    Amatrix = reshape(A, (dBond*dH, dBond));\n",
    "    return Amatrix;\n",
    "end;\n",
    "\n",
    "function leftUnpack(Amatrix)\n",
    "    dC, dBond = size(Amatrix);\n",
    "    dH = dC รท dBond;\n",
    "    A = reshape(Amatrix, (dBond, dH, dBond));\n",
    "    return A;\n",
    "end;\n",
    "\n",
    "function rightPack(A)\n",
    "    dBond, dH = size(A)[1:2];\n",
    "    Amatrix = reshape(A, (dBond, dBond*dH));\n",
    "end;\n",
    "\n",
    "function rightUnpack(Amatrix)\n",
    "    dBond, dC = size(Amatrix);\n",
    "    dH = dC รท dBond;\n",
    "    A = reshape(Amatrix, (dBond, dH, dBond));\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gauge-free QR\n",
    "**Nothing** works if we don't remove the gauge freedom in QR.\n",
    "We can't even switch to left/right-orthonormal forms from a uniform form as iterative methods don't converge\n",
    "due to sign flips.\n",
    "In the functions below I make sure that the diagonal elements in R are are non-negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "function qrGauged(a; tol=eps(Float64))\n",
    "    f = qr(a)\n",
    "    q = Matrix(f.Q);\n",
    "    r = f.R;\n",
    "    D = size(r)[1];\n",
    "    rDiag = zeros((D,D));\n",
    "    for i=1:D\n",
    "        check = r[i, i];\n",
    "        # If an item on the diagonal is negative,\n",
    "        # record that to flip signs later\n",
    "        if abs(check) > tol && real(check) < 0\n",
    "            rDiag[i, i] = -1;\n",
    "        else\n",
    "            rDiag[i,i] = 1;\n",
    "        end;\n",
    "    end;\n",
    "    # Flip signs now\n",
    "    r = rDiag * r;\n",
    "    q = q * rDiag;\n",
    "\n",
    "    return q, r;\n",
    "end;\n",
    "\n",
    "function rqGauged(a; tol=eps(Float64))\n",
    "    \n",
    "    # RQ from QR\n",
    "    # https://leohart.wordpress.com/2010/07/23/rq-decomposition-from-qr-decomposition/\n",
    "    reversed_a = reverse(a, dims=1);\n",
    "\n",
    "    f = qr(transpose(reversed_a));\n",
    "    q = Matrix(f.Q);\n",
    "    r = f.R;\n",
    "\n",
    "    r = reverse(transpose(r), dims=1);\n",
    "    r = reverse(r, dims=2);\n",
    "    q = reverse(transpose(q), dims=1);\n",
    "    \n",
    "    D = size(r)[2];\n",
    "    rDiag = zeros((D,D));\n",
    "    for i=1:D\n",
    "        check = r[i, i];\n",
    "        if abs(check) > tol && real(check) < 0\n",
    "            rDiag[i, i] = -1;\n",
    "        else\n",
    "            rDiag[i,i] = 1;\n",
    "        end;\n",
    "    end;\n",
    "    r = r * rDiag;\n",
    "    q = rDiag * q;\n",
    "    return r, q;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gauge-free SVD\n",
    "Julia (or Python) doesn't have an SVD-independent implementation of the polar decomposition which is needed for inverse-free TDVP.\n",
    "That it is dependent on SVD is potentially numerically unstable.\n",
    "Note that SVD is an intermediate step (in easy implementations) for the polar decomposition that is needed later, and is also necessary for two site TDVP to truncate the bond dimension (which this report doesn't do)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "function svdGauged(a; tol=eps(Float64))\n",
    "    F = svd(a);\n",
    "    u = F.U;\n",
    "    s = F.S;\n",
    "    vh = F.Vt;\n",
    "    # Form singular values as matrix\n",
    "    sMatrix = zeros((size(u)[2], size(vh)[1]));\n",
    "    for i=1:length(s)\n",
    "        sMatrix[i, i] = s[i];\n",
    "    end;\n",
    "    D = min(size(a)[1], size(a)[2]);\n",
    "    # Scan through left singular vectors\n",
    "    # Make first non-zero component real and positive\n",
    "    for i=1:D\n",
    "        ui = u[:, i];\n",
    "        mags = abs.(ui);\n",
    "        # Find the first component with magnitude larger than tol\n",
    "        idx = findfirst(mags .> tol);\n",
    "        val = ui[idx];\n",
    "        # Find its phase\n",
    "        angle = atan(imag(val), real(val));\n",
    "        # If the phase is not zero\n",
    "        if abs(angle) > tol\n",
    "            phase = exp(1im * angle);\n",
    "            # Multiply the columns of u with the opposite phase\n",
    "            u[:, i] *= conj(phase);\n",
    "            # Multiply the rows of vh with the phase\n",
    "            vh[i, :] *= phase;\n",
    "        end;\n",
    "\n",
    "        # Drop the imaginary part of the first non-zero element of u completely\n",
    "        u[idx, i] = real(u[idx, i]);\n",
    "    end;\n",
    "\n",
    "    return u, sMatrix, vh;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gauge-free polar decomposition\n",
    "This will be used to find $A_L, A_R$, given $A_C, C$.\n",
    "It's implemented through SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "function polarGauged(a; side=\"right\")\n",
    "    m, n = size(a);\n",
    "    k = min(m, n);\n",
    "    us, ss, vhs = svdGauged(a);\n",
    "    u = us[:, 1:k] * vhs[1:k, :];\n",
    "    if side == \"right\"\n",
    "        p = vhs'[:, 1:k] * ss[1:k, 1:k] * vhs[1:k, :];\n",
    "    elseif side == \"left\"\n",
    "        p = us[:, 1:k] * ss[1:k, 1:k] * us'[1:k, :];\n",
    "    end;\n",
    "\n",
    "    return u, p;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding canonical forms\n",
    "We're now ready to switch from a uniform gauge to the left-canonical or right-canonical form, or to their mixture, the mixed gauge.\n",
    "The algorithms for these don't need to be optimized as they are done once for the initial condition.\n",
    "They involve iterative methods in order to have nice convergences, avoiding square roots and inverses.\n",
    "\n",
    "## Left-canonical form *(Algorithm 1)*\n",
    "Given $A$, we want left-unitary $A_L$ and a matrix $L$ such that\n",
    "$$A_L L = L A$$\n",
    "holds.\n",
    "We solve this problem iteratively where each iteration has two main steps:\n",
    " * $A_L^{i+1}, \\tilde{L}^{i+1} = QR(L^i A)$\n",
    " * $L^{i+1} = $ fixedPoint($A_L^{{i+1}^\\dagger} \\tilde{L}^{i+1} A$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "function leftOrthonormalize(A; L0=nothing, tol=eps(Float64), resDiv=10)\n",
    "    dBond, dH = size(A)[1:2];\n",
    "    # If L0 is provided, take that as the initial guess\n",
    "    # Otherwise create a random matrix as L0\n",
    "    if L0 == nothing\n",
    "        # Get a random matrix\n",
    "        L = rand(ComplexF64, (dBond, dBond));\n",
    "        L /= norm(L);\n",
    "    else\n",
    "        # Take the provided guess but normalize it\n",
    "        L = copy(L0) / norm(L0);\n",
    "    end;\n",
    "    Lold = copy(L);\n",
    "    # First guess for A_L and L\n",
    "    @tensor LtimesA[i,j,k] := L[i,l] * A[l,j,k];\n",
    "    ALmatrix, L = qrGauged(leftPack(LtimesA))\n",
    "    AL = leftUnpack(ALmatrix);\n",
    "    normL = norm(L);\n",
    "    L /= normL;\n",
    "    res = maximum(abs.(L-Lold));\n",
    "    while res > tol\n",
    "        # Transfer map for the left fixed point\n",
    "        function leftFixedPointMap(Lguess)\n",
    "            @tensor contraction[k,l] := Lguess[i,j]*conj(AL)[i,m,k]*A[j,m,l];\n",
    "            return contraction;\n",
    "        end;\n",
    "        # Find its dominant eigenvector\n",
    "        # Note that the eigensolver tolerance increases gradually\n",
    "        L = eigsolve(leftFixedPointMap, L, tol=res/resDiv)[2][..,1];\n",
    "        # Refine with QR\n",
    "        L = qrGauged(L)[2];\n",
    "        L /= norm(L);\n",
    "        Lold = copy(L)\n",
    "        # Iterate with QR\n",
    "        @tensor LtimesA[i,j,k] = L[i,l] * A[l,j,k];\n",
    "        ALmatrix, L = qrGauged(leftPack(LtimesA))\n",
    "        AL = leftUnpack(ALmatrix);\n",
    "        normL = norm(L);\n",
    "        L /= normL;\n",
    "        res = maximum(abs.(L-Lold));\n",
    "    end;\n",
    "    \n",
    "    # A / normL would be a normalized site tensor\n",
    "    return AL, L, normL;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right-canonical form *(Algorithm 1)*\n",
    "Given $A$, we want right-unitary $A_R$ and a matrix $R$ such that\n",
    "$$R A_R = A R$$\n",
    "holds.\n",
    "We solve this problem similar to the left-canonical form.\n",
    "There are two main steps:\n",
    " * $\\tilde{R}^{i+1}, A_R^{i+1} = RQ(A R^i)$\n",
    " * $R^{i+1} = $ fixedPoint($A \\tilde{R}^{i+1} A_R^{{i+1}^\\dagger}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "function rightOrthonormalize(A; R0=nothing, tol=eps(Float64), resDiv=10)\n",
    "    dBond, dH = size(A)[1:2];\n",
    "    # If R0 is provided, take that as the initial guess\n",
    "    # Otherwise create a random matrix as R0\n",
    "    if R0 == nothing\n",
    "        # Get a random matrix\n",
    "        R = rand(ComplexF64, (dBond, dBond));\n",
    "        R /= norm(R);\n",
    "    else\n",
    "        # Take the provided guess but normalize it\n",
    "        R = copy(R0) / norm(R0);\n",
    "    end;\n",
    "    Rold = copy(R);\n",
    "    # First guess for A_R and R\n",
    "    @tensor AtimesR[i,j,k] := A[i,j,l] * R[l,k];\n",
    "    R, ARmatrix = rqGauged(rightPack(AtimesR))\n",
    "    AR = rightUnpack(ARmatrix);\n",
    "    normR = norm(R);\n",
    "    R /= normR;\n",
    "    res = maximum(abs.(R-Rold));\n",
    "    while res > tol\n",
    "        # Transfer map for the right fixed point\n",
    "        function rightFixedPointMap(Rguess)\n",
    "            @tensor contraction[i,j] := conj(AR)[j,m,l] * A[i,m,k] * Rguess[k,l];\n",
    "            return contraction;\n",
    "        end;\n",
    "        # Find its dominant eigenvector\n",
    "        # Note that the eigensolver tolerance increases gradually\n",
    "        R = eigsolve(rightFixedPointMap, R, tol=res/resDiv)[2][..,1];\n",
    "        # Refine with RQ\n",
    "        R = rqGauged(R)[1];\n",
    "        R /= norm(R);\n",
    "        Rold = copy(R)\n",
    "        # Iterate with RQ\n",
    "        @tensor AtimesR[i,j,k] = A[i,j,l] * R[l,k];\n",
    "        R, ARmatrix = rqGauged(rightPack(AtimesR))\n",
    "        AR = rightUnpack(ARmatrix);\n",
    "        normR = norm(R);\n",
    "        R /= normR;\n",
    "        res = maximum(abs.(R-Rold));\n",
    "    end;\n",
    "    \n",
    "    # A / normR would be a normalized site tensor\n",
    "    return AR, R, normR;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed form *(Algorithm 2)*\n",
    "We want to use $A_L$ and $A_R$ together. For that, we need a center-site tensor $A_C$, and the matrix $C$ which does\n",
    "$$ A_L C = A_C = C A_R.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mixedCanonical(A, tol=eps(Float64), resDiv=10)\n",
    "    dBond, dH = size(A)[1:2];\n",
    "    # Compute left and right orthonormal forms\n",
    "    AL, _, normA = leftOrthonormalize(A, tol=tol, resDiv=resDiv);\n",
    "    AR, C, _ = rightOrthonormalize(AL, tol=tol, resDiv=resDiv);\n",
    "    # Diagonalize C\n",
    "    u, C, vh = svdGauged(C);\n",
    "    # Absorb u and vh to AL and AR\n",
    "    @tensor AL[i,j,k] = u'[i,l]*AL[l,j,m]*u[m,k];\n",
    "    @tensor AR[i,j,k] = vh[i,l]*AR[l,j,m]*vh'[m,k];\n",
    "    # Compute AC\n",
    "    @tensor AC[i,j,k] := AL[i,j,l]*C[l,k];\n",
    "\n",
    "    return AL, AC, AR, C, normA;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity checks for canonical forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numbers below should be on the order of machine epsilon.\n",
      "Left orthonormality: 4.652682298944613e-16\n",
      "Uniform to left: 1.8253379971363983e-16\n",
      "Right orthonormality: 8.881784197001252e-16\n",
      "Uniform to right: 2.1179449947025655e-16\n",
      "Left/right to center: 7.850462293418876e-16\n"
     ]
    }
   ],
   "source": [
    "AL_, L = leftOrthonormalize(A)[1:2];\n",
    "AR_, R = rightOrthonormalize(A)[1:2];\n",
    "AL, AC, AR, C, normA = mixedCanonical(A);\n",
    "println(\"The numbers below should be on the order of machine epsilon.\")\n",
    "@tensor test[k,l] := conj(AL)[i,m,k] * AL[i,m,l];\n",
    "println(\"Left orthonormality: \", maximum(abs.(test-I)));\n",
    "@tensor test[i,j,k] := L[i,l] * A[l,j,k] / normA - AL_[i,j,l] * L[l,k];\n",
    "println(\"Uniform to left: \", maximum(abs.(test)));\n",
    "@tensor test[i,j] := conj(AR)[j,m,k] * AR[i,m,k];\n",
    "println(\"Right orthonormality: \", maximum(abs.(test-I)));\n",
    "@tensor test[i,j,k] := R[i,l] * AR_[l,j,k] - A[i,j,l] * R[l,k] / normA;\n",
    "println(\"Uniform to right: \", maximum(abs.(test)));\n",
    "@tensor test[i,j,k] := AL[i,j,l]*C[l,k] - C[i,l] * AR[l,j,k];\n",
    "println(\"Left/right to center: \", maximum(abs.(test)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding $A_L, A_R$ given $A_C, C$ *(Algorithm 5)*\n",
    "The \"inverse-free\" part of the algorithm is here.\n",
    "Time evolution is done for $A_C$ and $C$: From them, $A_L$ and $A_R$ found as the solutions that minimize\n",
    "\n",
    "$$||A_C - A_L C||_2,$$\n",
    "$$||A_C - C A_R||_2.$$\n",
    "\n",
    "These are solved simultaneously from the polar decompositions of $A_C$ and $C$, (part of) the proof is *Theorem IX.7.2* in *Matrix Analysis, Bhatia, 1952, Springer*, so-called a way of finding \"the best unitary approximation to a matrix.\"\n",
    "Alex and I have spent many hours trying to prove this result using this theorem, in the end we did, but I am not sure if I could prove it again\n",
    "quickly if I wanted to.\n",
    "I omit that proof here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "function minACC(AC, C)\n",
    "    # See \"Variational optimization algorithms for uniform matrix product states\"\n",
    "    # by Zauner-Stauber et al.\n",
    "    # for an explanation.\n",
    "    # arXiv: https://arxiv.org/abs/1701.07035\n",
    "    # PhysRevB: https://doi.org/10.1103/PhysRevB.97.045145\n",
    "\n",
    "    dBond, dH = size(AC)[1:2];\n",
    "    ULAC = leftUnpack(polarGauged(leftPack(AC), side=\"right\")[1])\n",
    "    ULC = polarGauged(C, side=\"right\")[1]\n",
    "    @tensor AL[i,j,k] := ULAC[i,j,l] * ULC'[l,k];\n",
    "    URAC = rightUnpack(polarGauged(rightPack(AC), side=\"left\")[1])\n",
    "    URC = polarGauged(C, side=\"left\")[1]\n",
    "    @tensor AR[i,j,k] := URC'[i,l] * URAC[l,j,k];\n",
    "\n",
    "    return AL, AR;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we get the same $A_L$ and $A_R$ from before when we use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numbers below should be on the order of machine epsilon.\n",
      "AL: 4.503336797797561e-16\n",
      "AR: 5.176433455214083e-15\n"
     ]
    }
   ],
   "source": [
    "AL_, AR_ = minACC(AC, C);\n",
    "println(\"The numbers below should be on the order of machine epsilon.\")\n",
    "println(\"AL: \", maximum(abs.(AL_-AL)));\n",
    "println(\"AR: \", maximum(abs.(AR_-AR)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effective Hamiltonian(s)\n",
    "This is the most elaborate part of the implementation. What follows are series of functions that, when stiched together, form the action of the Hamiltonian *and then* the MPS projector applied to a state.\n",
    "The end result is a matrix-free form of the effective Hamiltonian(s), which can then be exponentiated.\n",
    "There are in fact two such operators, one for $A_C$ ($G_1$) and one for $C$ ($G_2$).\n",
    "\n",
    "Note that the article has a rather serious \"accessibility\" problem:\n",
    "The first time they define these effective Hamiltonians (eqs. 170 and 172), they have $A_C$ and $C$ already acted on.\n",
    "That is, they are not Hamiltonians, they can't be exponentiated and then made to hit on $A_C$ and $C$.\n",
    "However, later they then have a change of mind and redefine them without $A_C$ and $C$ (without telling how to do it) in eqs. 174 and 175.\n",
    "Then they can be exponentiated.\n",
    "\n",
    "The functions below construct $G_1$ and $G_2$ as operators that are to act on $A_C$ and $C$.\n",
    "\n",
    "These involve iterative methods, most importantly in ```getLh``` and ```getRh``` to get around having to take inverses, and also in ```ELLp``` and ```ERRp``` to find the fixed points of the transfer tensors.\n",
    "One needs initial guesses for iterative methods, so for the case when there is none, these functions take the (pseudo) inverses (for ```getLh``` and ```getRh```) or use random guesses (for ```ELLp``` and ```ERRp```).\n",
    "For the subsequent timesteps the result of the last timestep can be given back as guesses, and they tend to converge in a few steps.\n",
    "This is why all the functions below have optional arguments with default values of \"nothing\".\n",
    "\n",
    "There is room for optimization in these, particularly where ```@tensor``` is called with ```:=```, as that reallocates memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function ELLp(AL; r0=nothing, tol=eps(Float64))\n",
    "    \"\"\"Computes (1 - T_L') where T_L' is the transfer tensor in the left\n",
    "    canonical form with the dominant component subtracted out.\n",
    "    \n",
    "    Part of the rhs of eq. (169)-1.\n",
    "    \"\"\"\n",
    "\n",
    "    dBond, dH = size(AL)[1:2];\n",
    "    # Compute the right fixed point of AL's transfer tensor\n",
    "    # Transfer tensor:\n",
    "    @tensor TL[i,j,k,l] :=  conj(AL)[j,m,l] * AL[i,m,k];\n",
    "    # Its action on the right fixed point\n",
    "    function rightFixedPointMap(rGuess)\n",
    "        @tensor contraction[i,j] := TL[i,j,k,l]*rGuess[k,l];\n",
    "        return contraction;\n",
    "    end;\n",
    "\n",
    "    if r0 == nothing\n",
    "        # Random Hermitian matrix\n",
    "        r = Matrix(Hermitian(rand(ComplexF64, (dBond, dBond))));\n",
    "    else\n",
    "        r = copy(r0);\n",
    "    end;\n",
    "    # Find the fixed point\n",
    "    r = eigsolve(rightFixedPointMap, r, tol=tol)[2][..,1];\n",
    "    # Normalize it with its trace\n",
    "    r /= tr(r);\n",
    "    # Make it exactly Hermitian\n",
    "    r = Matrix(Hermitian(r));\n",
    "\n",
    "    # Negate and remove the fixed point projector\n",
    "    @tensor domP[i,j,k,l] := r[i,j] * Matrix{ComplexF64}(I, dBond, dBond)[k,l];\n",
    "    TLPP = -TL + domP;\n",
    "    # Add identity\n",
    "    @tensor idP[i,j,k,l] := Matrix{ComplexF64}(I, dBond, dBond)[i,j] * Matrix{ComplexF64}(I, dBond, dBond)[k,l];\n",
    "    TLP = idP + TLPP;\n",
    "\n",
    "    return TLP, r;\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function ERRp(AR; l0=nothing, tol=eps(Float64))\n",
    "    \"\"\"Computes (1 - T_R') where T_R' is the transfer tensor in the right\n",
    "    canonical form with the dominant component subtracted out.\n",
    "    \n",
    "    Part of the rhs of eq. (169)-2.\n",
    "    \"\"\"\n",
    "\n",
    "    dBond, dH = size(AR)[1:2];\n",
    "    # Compute the left fixed point of AR's transfer tensor\n",
    "    @tensor TR[i,j,k,l] := conj(AR)[i,m,k] * AR[j,m,l];\n",
    "    # Its action on the left fixed point\n",
    "    function leftFixedPointMap(lGuess)\n",
    "        @tensor contraction[k,l] := lGuess[i,j]*TR[i,j,k,l];\n",
    "        return contraction;\n",
    "    end;\n",
    "\n",
    "    if l0 == nothing\n",
    "        # Random Hermitian matrix\n",
    "        l = Matrix(Hermitian(rand(ComplexF64, (dBond, dBond))));\n",
    "    else\n",
    "        l = copy(l0);\n",
    "    end;\n",
    "    \n",
    "    # Find the fixed point\n",
    "    l = eigsolve(leftFixedPointMap, l, tol=tol)[2][..,1];\n",
    "    # Normalize it with its trace\n",
    "    l /= tr(l);\n",
    "    # Make it exactly Hermitian\n",
    "    l = Matrix(Hermitian(l));\n",
    "\n",
    "    # Negate and remove the fixed point projector\n",
    "    @tensor domP[i,j,k,l] := Matrix{ComplexF64}(I, dBond, dBond)[i,j] * l[k,l];\n",
    "    TRPP = -TR + domP;\n",
    "    # Add identity\n",
    "    @tensor idP[i,j,k,l] := Matrix{ComplexF64}(I, dBond, dBond)[i,j] * Matrix{ComplexF64}(I, dBond, dBond)[k,l];\n",
    "    TRP = idP + TRPP;\n",
    "\n",
    "    return TRP, l;\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function getLh(AL, h; r0=nothing, Lh0=nothing, tol=eps(Float64))\n",
    "    \"\"\"Computes Lh in eq. (169), a contribution to the tangent space projector.\n",
    "        h is the local two site Hamiltonian.\n",
    "    \"\"\"\n",
    "\n",
    "    dBond, dH = size(AL)[1:2];\n",
    "    TLP, r = ELLp(AL, r0=r0);\n",
    "    # Contraction around the local Hamiltonian\n",
    "    @tensor hc[i,j] := conj(AL)[k,l,q] * conj(AL)[q,m,j] * h[l,m,n,o] * AL[k,n,p] * AL[p,o,i];\n",
    "\n",
    "    # Equation to be solved\n",
    "    function LhEq(Lhguess)\n",
    "        @tensor preres[k,l] := Lhguess[j,i] * TLP[i,j,k,l];\n",
    "        return preres - hc;\n",
    "    end;\n",
    "\n",
    "    if Lh0 == nothing\n",
    "        # Compute the inverse\n",
    "        Lh = Matrix(transpose(reshape(transpose(reshape(hc, (dBond^2)))*pinv(reshape(TLP, (dBond^2, dBond^2))),(dBond, dBond))));\n",
    "    else\n",
    "        Lh = copy(Lh0);\n",
    "    end;\n",
    "\n",
    "    Lh = linsolve(LhEq, zeros(ComplexF64, size(Lh)), Lh, tol=tol)[1];\n",
    "    sol = Matrix(Hermitian(reshape(Lh, (dBond, dBond))));\n",
    "\n",
    "    return sol, r;\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function getRh(AR, h; l0=nothing, Rh0=nothing, tol=eps(Float64))\n",
    "    \"\"\"Computes Rh in eq. (169), a contribution to the tangent space projector.\n",
    "        h is the local two site Hamiltonian.\n",
    "    \"\"\"\n",
    "\n",
    "    dBond, dH = size(AR)[1:2];\n",
    "    TRP, l = ERRp(AR, l0=l0);\n",
    "    # Contraction around the local Hamiltonian\n",
    "    @tensor hc[k,l] := conj(AR)[k,i,p] * conj(AR)[p,j,q] * h[i,j,m,n] * AR[l,m,o] * AR[o,n,q];\n",
    "\n",
    "    # Equation to be solved\n",
    "    function RhEq(Rhguess)\n",
    "        @tensor preres[i,j] := TRP[i,j,k,l] * Rhguess[l,k];\n",
    "        return preres - hc;\n",
    "    end;\n",
    "\n",
    "    if Rh0 == nothing\n",
    "        # Compute the inverse\n",
    "        Rh = Matrix(transpose(reshape(pinv(reshape(TRP, (dBond^2, dBond^2)))*reshape(hc, (dBond^2)),(dBond, dBond))));\n",
    "    else\n",
    "        Rh = copy(Rh0);\n",
    "    end;\n",
    "    \n",
    "    Rh = linsolve(RhEq, zeros(ComplexF64, size(Rh)), Rh, tol=tol)[1];\n",
    "    sol = Matrix(Hermitian(Rh));\n",
    "\n",
    "    return sol, l;\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function getG1L(AL, h)\n",
    "    \"\"\"Computes acting-from-left part of G_1 in eq. (170) (second term).\n",
    "        So this would hit on A_C to the right.\n",
    "        Part of the tangent space projector.\n",
    "    \"\"\"\n",
    "\n",
    "    dBond, dH = size(AL)[1:2];\n",
    "    @tensor G1L[i,j,k,l] := conj(AL)[m,n,i]*h[n,j,p,l]*AL[m,p,k];\n",
    "\n",
    "    # This is supposed to be Hermitian.\n",
    "    G1Lmatrix = Matrix(Hermitian(reshape(G1L, (dH * dBond, dH * dBond))));\n",
    "    G1L = reshape(G1Lmatrix, (dBond, dH, dBond, dH));\n",
    "\n",
    "    return G1L;\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function getG1R(AR, h)\n",
    "    \"\"\"Computes acting-from-right part of G_1 in eq. (170) (first term).\n",
    "        So this would hit on A_C to the left.\n",
    "        Part of the tangent space projector.\n",
    "    \"\"\"\n",
    "\n",
    "    dBond, dH = size(AR)[1:2];\n",
    "    @tensor G1R[i,j,k,l] := conj(AR)[l,o,m] * h[k,o,i,p] * AR[j,p,m];\n",
    "\n",
    "    # This is supposed to be Hermitian.\n",
    "    G1Rmatrix = Matrix(Hermitian(reshape(G1R, (dH * dBond, dH * dBond))));\n",
    "    G1R = reshape(G1Rmatrix,(dH,dBond,dH,dBond));\n",
    "\n",
    "    return G1R;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is for the time evolution fo $C$.\n",
    "It is related to $G_2$ in eq. 172, but what is in the article is really not convincing when one looks at the tangent space projector in eq. 91.\n",
    "Why would one contract with $A_L$ (eq. 172) specifically?\n",
    "Why not $A_R$?\n",
    "Looking at eq. 91, I constructed $G_2$ myself analogously to eq. 170.\n",
    "Its last two terms are both there, but only one term in place of the first two terms is there, where $C$ goes in between $A_L$ and $A_R$.\n",
    "The function below defines this latter operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function getG2M(AL, AR, h)\n",
    "    \"\"\"Computes part of G_2 eq. (172).\n",
    "        This would take C in the \"middle\".\n",
    "        This doesn't exist in the article directly, to understand,\n",
    "        see the tangent space projector in eq. 91.\n",
    "    \"\"\"\n",
    "\n",
    "    dBond, dH = size(AL)[1:2];\n",
    "    @tensor G2M[i,j,k,l] := conj(AL)[m,n,i] * conj(AR)[j,o,r] * h[n,o,p,q] * AL[m,p,k] * AR[l,q,r];\n",
    "\n",
    "    # This is supposed to be Hermitian.\n",
    "    G2Mmatrix = Matrix(Hermitian(reshape(G2M, (dBond^2, dBond^2))));\n",
    "    G2M = reshape(G2Mmatrix,(dBond, dBond, dBond, dBond));\n",
    "    \n",
    "    return G2M;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamiltonian\n",
    "Before we move on with the time evolution, we need a Hamiltonian.\n",
    "Here, I define a general nearest-neighbour type Hamiltonian for two-state systems, without quantum number conservation.\n",
    "Generalizing to next-neighbour Hamiltonians may require a change in the definition of the effective Hamiltonian.\n",
    "Larger local Hilbert spaces with nearest-neighbour interactions, again without quantum number conservation, should still work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pauli operators\n",
    "Sx = 0.5*[0 1; 1 0];\n",
    "Sy = 0.5*1im * [0 -1; 1 0];\n",
    "Sz = 0.5*[1 0; 0 -1];\n",
    "identity = Matrix{ComplexF64}(I, 2, 2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function hamiltonian(;jx=0, jy=0, jz=1.0, hx=1.0, hy=0, hz=0.4)\n",
    "    \"\"\"Hamiltonian for\n",
    "        j_i S_i S_{i+1} + h_i S_i\n",
    "        type interactions.\n",
    "\n",
    "        ham[ijkl] = <ij|H|kl>.\n",
    "    \"\"\"\n",
    "\n",
    "    ham = zeros(Complex{Float64},(2, 2, 2, 2));\n",
    "    function addTerm(op1, op2)\n",
    "        @tensor res[i,j,k,l] := op1[i,k]*op2[j,l];\n",
    "        return res;\n",
    "    end;\n",
    "        \n",
    "    ham += jx * addTerm(Sx,Sx);\n",
    "    ham += jy * addTerm(Sy,Sy);\n",
    "    ham += jz * addTerm(Sz,Sz);\n",
    "    ham += hx * addTerm(Sx,identity);\n",
    "    ham += hy * addTerm(Sy,identity);\n",
    "    ham += hz * addTerm(Sz,identity);\n",
    "\n",
    "    return ham;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time stepper\n",
    "We have everything we need for time evolution.\n",
    "The equations of motion for $A_C$ and $C$ are\n",
    "\n",
    "$$\\dot{A_C} = -i G_1[A_L,A_R] A_C,$$\n",
    "$$\\dot{C} = +i G_2[A_L, A_R] C.$$\n",
    "\n",
    "Note the sign difference.\n",
    "I made explicit the $A_L$ and $A_R$ dependence of the operators in brackets.\n",
    "Now comes the \"magic\".\n",
    "The basic time step of $\\delta t$ is made with\n",
    " * $A_C(t+\\delta t) = e^{-i G_1[A_L(t), A_R(t)]\\, \\delta t} A_C(t)$\n",
    " * $C(t+\\delta t) = e^{-i G_2[A_L(t), A_R(t)]\\, \\delta t} C(t)$\n",
    " * $A_L(t+\\delta t), A_R(t+\\delta t) = \\text{minACC}(AC(t+\\delta t, C(t+\\delta t))$\n",
    "\n",
    "Note that the exponents have the same sign, unlike before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function eulerStepExp(AL, AC, AR, C, h; tstep=0.01, l0=nothing, r0=nothing, Lh0=nothing, Rh0=nothing, tol=eps(Float64))\n",
    "    \"\"\"Time evolve AC and C, use them to find evolved AL, AR.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The four parts of G_1\n",
    "    G1L = getG1L(AL, h);\n",
    "    G1R = getG1R(AR, h);\n",
    "    Lh, r = getLh(AL, h, r0=r0, Lh0=Lh0);\n",
    "    Rh, l = getRh(AR, h, l0=l0, Rh0=Rh0);\n",
    "\n",
    "    function hamAC(AC_)\n",
    "        res = zeros(ComplexF64,(dBond,dH,dBond));\n",
    "        @tensor res[i,j,m] += G1L[i,j,k,l] * AC_[k,l,m];\n",
    "        @tensor res[i,l,m] += AC_[i,j,k] * G1R[j,k,l,m];\n",
    "        @tensor res[i,k,l] += Lh[i,j]  * AC_[j,k,l];\n",
    "        @tensor res[i,j,l] += AC_[i,j,k] * Rh[k,l];\n",
    "        \n",
    "        return res;\n",
    "    end;\n",
    "\n",
    "    # Forward AC\n",
    "    AC_ = exponentiate(hamAC,-1im * tstep, AC,ishermitian=true,tol=tol / abs(tstep))[1];\n",
    "    \n",
    "    # The three parts of G_2\n",
    "    G2M = getG2M(AL, AR, h);\n",
    "    function hamC(C_)\n",
    "        res = zeros(ComplexF64,(dBond,dBond));\n",
    "        @tensor res[i,j] += G2M[i,j,k,l] * C_[k,l];\n",
    "        @tensor res[i,k] += Lh[i,j] * C_[j,k];\n",
    "        @tensor res[i,k] += C_[i,j] * Rh[j,k];\n",
    "\n",
    "        return res;\n",
    "        \n",
    "    end;\n",
    "    \n",
    "    # Backward C\n",
    "    C_ = exponentiate(hamC,-1im * tstep,C,ishermitian=true,tol=tol / abs(tstep))[1];\n",
    "\n",
    "    # Find evolved A_L and A_R using evolved A_C and C\n",
    "    AL_, AR_ = minACC(AC_, C_);\n",
    "\n",
    "    return AL_, AC_, AR_, C_, l, r, Lh, Rh;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the time stepper\n",
    "\n",
    "Since we have a finite-chain TDVP code, we can test against it.\n",
    "The observables should agree, and further, for my dynamical systems related demands, everything should evolve continously.\n",
    "\n",
    "*To be continued. The Python implementation had passed the tests.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = hamiltonian();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_, AC_, AR_, C_, l, r, Lh, Rh = eulerStepExp(AL, AC, AR, C, h, tstep=0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
